{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 邏輯斯迴歸\n",
    "## 目錄\n",
    "---\n",
    "1. Introduction\n",
    "2. 資料預處理\n",
    "3. 建置模型\n",
    "4. 模型評估\n",
    "5. 參考資源\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "邏輯斯迴歸模型是在機器學習中常見的分類模型，專門用來處理類別型資料，而其中又分為Binary Classification以及Multi-class Classification\n",
    "\n",
    "於原理上，可以發現邏輯斯迴歸模型與線性迴歸模型很像，都是要找到一條線來進行預測。然而，使用上的意義卻是完全不同，對於邏輯斯回歸而言，我們找到的這條線是想要將資料點在一個空間中能夠切出不同分類的結果，透過最大似然估計的方式預估這條線的係數。\n",
    "\n",
    "其中，羅吉斯迴歸用到的logit函數，也被稱作Sigmoid函數，在深度學習領域常被拿來使用或是比較，可以將任意輸入值輸出成0到1之間的函數\n",
    "\n",
    "sigmoid: $ σ(x)= \\frac{e^{x}}{1+e^{x}} \\ = \\frac{1}{1+e^{-x}} \\ $\n",
    "\n",
    "寫過來我們的機率函數變成\n",
    "$ p(x) = \\frac{1}{1 + e^{-(β_0+β_1x_1+β_2x_2+...+β_px_p)}} = σ(β_0+β_1x_1+β_2x_2+...+β_px_p)  $\n",
    "\n",
    "轉換為邏輯斯回歸的形式 $ logit(p) = log(odds) = log(\\frac{p(x)}{1-p(x)}) = β_0+β_1x_1+β_2x_2+...+β_px_p $\n",
    "\n",
    "羅吉斯回歸方程式將類別型態的反應變數轉換為事件的 log odds 值，也就是$ log⟮\\frac {P_i}{1−P_i})$\n",
    "⟯，來預測與自變數($X_1~X_n$) 的線性關係，接下來邏輯斯迴歸模型將會用最大概似估計法求解，並且找出最佳的 Beta 估計值，通常這個步驟就會交由我們偉大的 sklearn 來幫我們完成！\n",
    "\n",
    "-----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在我們要使用 sklearn 中的一個資料集 - breast_cancer，用來示範邏輯斯回歸模型的使用，該資料集用不同的照片轉數據的特徵來判斷該病患是否罹患乳癌（良性：benign（1），惡性：malignant (0)），該分析的資料屬於 Binary Classification。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(breast_cancer.data, columns = breast_cancer.feature_names)\n",
    "y = pd.DataFrame(breast_cancer.target, columns = ['target'])\n",
    "data = pd.concat([x, y], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "該資料中有 569 筆資料，且當中有 357 筆良性的資料以及 212 筆惡性的資料\n",
    "從資料敘述來看，可以發現資料間彼此的尺度差異相當大，因此可以先進行標準化的預處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension      target  \n",
       "count               569.000000  569.000000  \n",
       "mean                  0.083946    0.627417  \n",
       "std                   0.018061    0.483918  \n",
       "min                   0.055040    0.000000  \n",
       "25%                   0.071460    0.000000  \n",
       "50%                   0.080040    1.000000  \n",
       "75%                   0.092080    1.000000  \n",
       "max                   0.207500    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "檢查遺漏值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "target                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 資料預處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "為了避免後續的預測及避免模型 underfitting/overfitting，我們將資料切分成訓練集與測試集。另一方面，為了不使資料維度大小影響預測結果，我們也將資料進行標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_std = scaler.transform(x_train)\n",
    "x_test_std = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 建置模型\n",
    "我們使用 sklearn 套件中的 logistic regression 演算法進行分類器訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 sklearn 中的 logistic regression 預測時，參數可以選擇是否使用 l1、l2、elasticnet 作為 penalty，再將我們的 training data 作為 fitting 的資料，接著即可訓練出我們的分類器，並用 clf 變數來保存已經 train 好的分類器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty = 'l2').fit(x_train_std, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用已訓練好的分類器我們可以傳入 test data，並且可以回傳分類器對於每筆預測資料的判斷是否為良性的機率為多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.14327437e-01, 8.85672563e-01],\n",
       "       [9.99990961e-01, 9.03924655e-06],\n",
       "       [9.96901657e-01, 3.09834256e-03],\n",
       "       [5.10962742e-04, 9.99489037e-01],\n",
       "       [6.08832659e-05, 9.99939117e-01],\n",
       "       [1.00000000e+00, 9.60957939e-11],\n",
       "       [9.99999998e-01, 1.57079869e-09],\n",
       "       [9.64865916e-01, 3.51340843e-02],\n",
       "       [3.80706222e-01, 6.19293778e-01],\n",
       "       [7.64631525e-04, 9.99235368e-01],\n",
       "       [4.99839028e-02, 9.50016097e-01],\n",
       "       [9.87575163e-01, 1.24248369e-02],\n",
       "       [6.06878983e-03, 9.93931210e-01],\n",
       "       [8.54313105e-01, 1.45686895e-01],\n",
       "       [1.62971784e-03, 9.98370282e-01],\n",
       "       [9.99238536e-01, 7.61463718e-04],\n",
       "       [1.86082231e-03, 9.98139178e-01],\n",
       "       [1.13194456e-05, 9.99988681e-01],\n",
       "       [8.28917830e-07, 9.99999171e-01],\n",
       "       [9.99998857e-01, 1.14290643e-06],\n",
       "       [8.43948057e-02, 9.15605194e-01],\n",
       "       [9.78011338e-03, 9.90219887e-01],\n",
       "       [9.99999996e-01, 4.43242454e-09],\n",
       "       [7.95067460e-05, 9.99920493e-01],\n",
       "       [1.14707895e-03, 9.98852921e-01],\n",
       "       [5.81454037e-04, 9.99418546e-01],\n",
       "       [1.08567019e-03, 9.98914330e-01],\n",
       "       [6.05359802e-03, 9.93946402e-01],\n",
       "       [2.87092945e-03, 9.97129071e-01],\n",
       "       [9.99991884e-01, 8.11567745e-06],\n",
       "       [5.19676319e-04, 9.99480324e-01],\n",
       "       [1.49374957e-04, 9.99850625e-01],\n",
       "       [2.20755450e-03, 9.97792446e-01],\n",
       "       [5.51437830e-03, 9.94485622e-01],\n",
       "       [1.42126518e-04, 9.99857873e-01],\n",
       "       [2.44899064e-03, 9.97551009e-01],\n",
       "       [9.42146624e-01, 5.78533757e-02],\n",
       "       [2.95461139e-03, 9.97045389e-01],\n",
       "       [9.99910371e-01, 8.96287263e-05],\n",
       "       [4.83425478e-02, 9.51657452e-01],\n",
       "       [7.20347691e-05, 9.99927965e-01],\n",
       "       [9.99595048e-01, 4.04951942e-04],\n",
       "       [2.48409208e-03, 9.97515908e-01],\n",
       "       [9.72761248e-04, 9.99027239e-01],\n",
       "       [2.02024192e-02, 9.79797581e-01],\n",
       "       [7.26565144e-02, 9.27343486e-01],\n",
       "       [4.05706433e-04, 9.99594294e-01],\n",
       "       [4.97868115e-04, 9.99502132e-01],\n",
       "       [3.07948593e-02, 9.69205141e-01],\n",
       "       [6.14207325e-04, 9.99385793e-01],\n",
       "       [9.99879512e-01, 1.20487572e-04],\n",
       "       [9.99999946e-01, 5.39214820e-08],\n",
       "       [3.09248099e-01, 6.90751901e-01],\n",
       "       [1.32946353e-02, 9.86705365e-01],\n",
       "       [2.75706408e-05, 9.99972429e-01],\n",
       "       [9.65445202e-03, 9.90345548e-01],\n",
       "       [1.14013654e-04, 9.99885986e-01],\n",
       "       [1.00000000e+00, 7.57322606e-12],\n",
       "       [8.36673695e-01, 1.63326305e-01],\n",
       "       [1.40647742e-04, 9.99859352e-01],\n",
       "       [5.03181107e-03, 9.94968189e-01],\n",
       "       [9.99999548e-01, 4.51640524e-07],\n",
       "       [9.99999999e-01, 1.43172412e-09],\n",
       "       [3.12994626e-02, 9.68700537e-01],\n",
       "       [8.32707615e-04, 9.99167292e-01],\n",
       "       [1.31388775e-01, 8.68611225e-01],\n",
       "       [9.99986032e-01, 1.39683716e-05],\n",
       "       [9.99999998e-01, 2.39924291e-09],\n",
       "       [8.10899975e-04, 9.99189100e-01],\n",
       "       [2.05757338e-02, 9.79424266e-01],\n",
       "       [9.98669087e-01, 1.33091320e-03],\n",
       "       [9.98406146e-01, 1.59385411e-03],\n",
       "       [2.56748975e-03, 9.97432510e-01],\n",
       "       [9.95437725e-01, 4.56227475e-03],\n",
       "       [9.06469400e-05, 9.99909353e-01],\n",
       "       [1.07203480e-02, 9.89279652e-01],\n",
       "       [2.00446227e-02, 9.79955377e-01],\n",
       "       [4.86711890e-01, 5.13288110e-01],\n",
       "       [2.76538074e-05, 9.99972346e-01],\n",
       "       [1.38343458e-02, 9.86165654e-01],\n",
       "       [9.95674527e-01, 4.32547255e-03],\n",
       "       [6.46880068e-05, 9.99935312e-01],\n",
       "       [7.76385283e-01, 2.23614717e-01],\n",
       "       [9.99999990e-01, 1.00888320e-08],\n",
       "       [9.96074572e-01, 3.92542797e-03],\n",
       "       [9.98872988e-01, 1.12701170e-03],\n",
       "       [9.99863882e-01, 1.36118315e-04],\n",
       "       [9.99859360e-01, 1.40640356e-04],\n",
       "       [2.21027340e-04, 9.99778973e-01],\n",
       "       [3.40509556e-03, 9.96594904e-01],\n",
       "       [5.63251871e-03, 9.94367481e-01],\n",
       "       [3.24368926e-01, 6.75631074e-01],\n",
       "       [3.39964495e-02, 9.66003551e-01],\n",
       "       [2.88352672e-04, 9.99711647e-01],\n",
       "       [3.94851322e-04, 9.99605149e-01],\n",
       "       [1.32856877e-04, 9.99867143e-01],\n",
       "       [9.99999313e-01, 6.86620790e-07],\n",
       "       [9.99999018e-01, 9.82034799e-07],\n",
       "       [8.27285068e-05, 9.99917271e-01],\n",
       "       [9.99672237e-01, 3.27763226e-04],\n",
       "       [9.96852698e-01, 3.14730192e-03],\n",
       "       [1.60563396e-06, 9.99998394e-01],\n",
       "       [9.99983706e-01, 1.62935126e-05],\n",
       "       [9.99397606e-01, 6.02393712e-04],\n",
       "       [1.00704109e-02, 9.89929589e-01],\n",
       "       [3.49243740e-02, 9.65075626e-01],\n",
       "       [5.78538849e-03, 9.94214612e-01],\n",
       "       [1.00000000e+00, 1.21840949e-10],\n",
       "       [1.13142359e-01, 8.86857641e-01],\n",
       "       [3.21354716e-02, 9.67864528e-01],\n",
       "       [9.99330806e-01, 6.69193975e-04],\n",
       "       [1.31619714e-03, 9.98683803e-01],\n",
       "       [5.40131625e-01, 4.59868375e-01],\n",
       "       [1.00000000e+00, 7.39093832e-13]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = clf.predict(x_test_std)\n",
    "clf.predict_proba(x_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，我們可以根據模型的結果來試著解釋模型怎麼判斷結果，簡單的思考：\n",
    "- 若係數為正，代表該 feature 對於模型判斷是否為某 class 有正面的影響\n",
    "- 若係數為負，則相反\n",
    "- 如果將係數取絕對值，絕對值越大，代表影響力越深\n",
    "\n",
    "我們可以看一下這個模型的係數，從絕對值大小來看的話，可以發現一些比較重要的係數：\n",
    "- worst fractal dimension\n",
    "- worst texture\n",
    "- radius error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius : -0.4278961538648447\n",
      "mean texture : -0.39391342772061894\n",
      "mean perimeter : -0.38955025196393467\n",
      "mean area : -0.4643161782501586\n",
      "mean smoothness : -0.06675416301240449\n",
      "mean compactness : 0.5421062471173778\n",
      "mean concavity : -0.7967712717964242\n",
      "mean concave points : -1.1170207006060744\n",
      "mean symmetry : 0.23571256580891012\n",
      "mean fractal dimension : 0.07670116596628937\n",
      "radius error : -1.2711472154818992\n",
      "texture error : 0.18863977214458338\n",
      "perimeter error : -0.6093658073827845\n",
      "area error : -0.9097997916544213\n",
      "smoothness error : -0.31246106295015347\n",
      "compactness error : 0.6859722927398422\n",
      "concavity error : 0.1808153111531741\n",
      "concave points error : -0.31769168455369595\n",
      "symmetry error : 0.4999797593469267\n",
      "fractal dimension error : 0.6134054116708012\n",
      "worst radius : -0.8786104347308605\n",
      "worst texture : -1.3421882977984922\n",
      "worst perimeter : -0.5875570664037004\n",
      "worst area : -0.846559237388473\n",
      "worst smoothness : -0.549944585684143\n",
      "worst compactness : 0.005207050188346125\n",
      "worst concavity : -0.9457137512065071\n",
      "worst concave points : -0.7734362141127026\n",
      "worst symmetry : -1.2085312550964924\n",
      "worst fractal dimension : -0.1541604011999586\n"
     ]
    }
   ],
   "source": [
    "coef = clf.coef_[0]\n",
    "for i in range(len(data.columns[:-1])):\n",
    "     print(data.columns[i],\":\", coef[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型評估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用 confusion matrix 、accuracy 、 recall 、 f1-score 來評估訓練好的分類器好壞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print(\"Accuracy score:\", clf.score(x_test_std, y_test))\n",
    "matric = confusion_matrix(y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(matric,square=True,annot=True,cbar=False)\n",
    "plt.xlabel(\"predict value\")\n",
    "plt.ylabel(\"true value\")\n",
    "plt.title(\"confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          良性       0.97      0.99      0.98        71\n",
      "          惡性       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"report:\\n\",classification_report(y_test,predict,labels=[1,0],target_names=[\"良性\",\"惡性\"])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外，對於這種分類模型，也可以使用 ROC curve 以及 AUC 來評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(clf, x_test_std, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "綜合不同模型的衡量指標來看，可以發現使用邏輯斯回歸的成效不錯，對於乳癌的預測具有良好的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 參考資源\n",
    "- RPubs Logistic Regression Ginger Zhan\n",
    "https://rpubs.com/ginger_zhan/logistic_regression\n",
    "- sklearn logisticRegreesion\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "- 機器學習-邏輯回歸(Logistic Regression)\n",
    "http://www.taroballz.com/2018/07/18/ML_LogisticRegression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
